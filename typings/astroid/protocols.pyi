"""
This type stub file was generated by pyright.
"""

from collections.abc import Callable, Generator
from typing import Any, TYPE_CHECKING, TypeVar
from astroid import decorators, nodes, util
from astroid.context import InferenceContext
from astroid.nodes import node_classes
from astroid.typing import ConstFactoryResult, InferenceResult, SuccessfulInferenceResult

"""This module contains a set of functions to handle python protocols for nodes
where it makes sense.
"""
if TYPE_CHECKING:
    _TupleListNodeT = TypeVar("_TupleListNodeT", nodes.Tuple, nodes.List)
_CONTEXTLIB_MGR = ...
_UNARY_OPERATORS: dict[str, Callable[[Any], Any]] = ...
def tuple_infer_unary_op(self, op): # -> ConstFactoryResult:
    ...

def list_infer_unary_op(self, op): # -> ConstFactoryResult:
    ...

def set_infer_unary_op(self, op): # -> ConstFactoryResult:
    ...

def const_infer_unary_op(self, op): # -> ConstFactoryResult:
    ...

def dict_infer_unary_op(self, op): # -> ConstFactoryResult:
    ...

BIN_OP_IMPL = ...
@decorators.yes_if_nothing_inferred
def const_infer_binary_op(self: nodes.Const, opnode: nodes.AugAssign | nodes.BinOp, operator: str, other: InferenceResult, context: InferenceContext, _: SuccessfulInferenceResult) -> Generator[ConstFactoryResult | util.UninferableBase]:
    ...

@decorators.yes_if_nothing_inferred
def tl_infer_binary_op(self: _TupleListNodeT, opnode: nodes.AugAssign | nodes.BinOp, operator: str, other: InferenceResult, context: InferenceContext, method: SuccessfulInferenceResult) -> Generator[_TupleListNodeT | nodes.Const | util.UninferableBase]:
    """Infer a binary operation on a tuple or list.

    The instance on which the binary operation is performed is a tuple
    or list. This refers to the left-hand side of the operation, so:
    'tuple() + 1' or '[] + A()'
    """
    ...

@decorators.yes_if_nothing_inferred
def instance_class_infer_binary_op(self: nodes.ClassDef, opnode: nodes.AugAssign | nodes.BinOp, operator: str, other: InferenceResult, context: InferenceContext, method: SuccessfulInferenceResult) -> Generator[InferenceResult]:
    ...

@decorators.raise_if_nothing_inferred
def for_assigned_stmts(self: nodes.For | nodes.Comprehension, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

def sequence_assigned_stmts(self: nodes.Tuple | nodes.List, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

def assend_assigned_stmts(self: nodes.AssignName | nodes.AssignAttr, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

def arguments_assigned_stmts(self: nodes.Arguments, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

@decorators.raise_if_nothing_inferred
def assign_assigned_stmts(self: nodes.AugAssign | nodes.Assign | nodes.AnnAssign | nodes.TypeAlias, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

def assign_annassigned_stmts(self: nodes.AnnAssign, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

@decorators.raise_if_nothing_inferred
def excepthandler_assigned_stmts(self: nodes.ExceptHandler, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    ...

@decorators.raise_if_nothing_inferred
def with_assigned_stmts(self: nodes.With, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    """Infer names and other nodes from a *with* statement.

    This enables only inference for name binding in a *with* statement.
    For instance, in the following code, inferring `func` will return
    the `ContextManager` class, not whatever ``__enter__`` returns.
    We are doing this intentionally, because we consider that the context
    manager result is whatever __enter__ returns and what it is binded
    using the ``as`` keyword.

        class ContextManager(object):
            def __enter__(self):
                return 42
        with ContextManager() as f:
            pass

        # ContextManager().infer() will return ContextManager
        # f.infer() will return 42.

    Arguments:
        self: nodes.With
        node: The target of the assignment, `as (a, b)` in `with foo as (a, b)`.
        context: Inference context used for caching already inferred objects
        assign_path:
            A list of indices, where each index specifies what item to fetch from
            the inference results.
    """
    ...

@decorators.raise_if_nothing_inferred
def named_expr_assigned_stmts(self: nodes.NamedExpr, node: node_classes.AssignedStmtsPossibleNode, context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    """Infer names and other nodes from an assignment expression."""
    ...

@decorators.yes_if_nothing_inferred
def starred_assigned_stmts(self: nodes.Starred, node: node_classes.AssignedStmtsPossibleNode = ..., context: InferenceContext | None = ..., assign_path: list[int] | None = ...) -> Any:
    """
    Arguments:
        self: nodes.Starred
        node: a node related to the current underlying Node.
        context: Inference context used for caching already inferred objects
        assign_path:
            A list of indices, where each index specifies what item to fetch from
            the inference results.
    """
    ...

@decorators.yes_if_nothing_inferred
def match_mapping_assigned_stmts(self: nodes.MatchMapping, node: nodes.AssignName, context: InferenceContext | None = ..., assign_path: None = ...) -> Generator[nodes.NodeNG]:
    """Return empty generator (return -> raises StopIteration) so inferred value
    is Uninferable.
    """
    ...

@decorators.yes_if_nothing_inferred
def match_star_assigned_stmts(self: nodes.MatchStar, node: nodes.AssignName, context: InferenceContext | None = ..., assign_path: None = ...) -> Generator[nodes.NodeNG]:
    """Return empty generator (return -> raises StopIteration) so inferred value
    is Uninferable.
    """
    ...

@decorators.yes_if_nothing_inferred
def match_as_assigned_stmts(self: nodes.MatchAs, node: nodes.AssignName, context: InferenceContext | None = ..., assign_path: None = ...) -> Generator[nodes.NodeNG]:
    """Infer MatchAs as the Match subject if it's the only MatchCase pattern
    else raise StopIteration to yield Uninferable.
    """
    ...

@decorators.yes_if_nothing_inferred
def generic_type_assigned_stmts(self: nodes.TypeVar | nodes.TypeVarTuple | nodes.ParamSpec, node: nodes.AssignName, context: InferenceContext | None = ..., assign_path: None = ...) -> Generator[nodes.NodeNG]:
    """Hack. Return any Node so inference doesn't fail
    when evaluating __class_getitem__. Revert if it's causing issues.
    """
    ...
