"""
This type stub file was generated by pyright.
"""

from dataclasses import dataclass
from typing import Any, AsyncGenerator, Dict, Iterable, Iterator, List, Optional, Set, Union
from abc import ABC, abstractmethod
from pydantic import BaseModel

"""
This type stub file was generated by pyright.
"""
CONVERSATION_NAME_LENGTH = ...
@dataclass
class Usage:
    input: Optional[int] = ...
    output: Optional[int] = ...
    details: Optional[Dict[str, Any]] = ...


@dataclass
class Attachment:
    type: Optional[str] = ...
    path: Optional[str] = ...
    url: Optional[str] = ...
    content: Optional[bytes] = ...
    _id: Optional[str] = ...
    def id(self):
        ...
    
    def resolve_type(self):
        ...
    
    def content_bytes(self):
        ...
    
    def base64_content(self):
        ...
    
    @classmethod
    def from_row(cls, row):
        ...
    


@dataclass
class Prompt:
    prompt: str
    model: Model
    attachments: Optional[List[Attachment]]
    system: Optional[str]
    prompt_json: Optional[str]
    options: Options
    def __init__(self, prompt, model, *, attachments=..., system=..., prompt_json=..., options=...) -> None:
        ...
    


@dataclass
class _BaseConversation:
    model: _BaseModel
    id: str = ...
    name: Optional[str] = ...
    responses: List[_BaseResponse] = ...
    @classmethod
    def from_row(cls, row):
        ...
    


@dataclass
class Conversation(_BaseConversation):
    def prompt(self, prompt: Optional[str], *, attachments: Optional[List[Attachment]] = ..., system: Optional[str] = ..., stream: bool = ..., **options) -> Response:
        ...
    


@dataclass
class AsyncConversation(_BaseConversation):
    def prompt(self, prompt: Optional[str], *, attachments: Optional[List[Attachment]] = ..., system: Optional[str] = ..., stream: bool = ..., **options) -> AsyncResponse:
        ...
    


class _BaseResponse:
    """Base response class shared between sync and async responses"""
    prompt: Prompt
    stream: bool
    conversation: Optional[_BaseConversation] = ...
    def __init__(self, prompt: Prompt, model: _BaseModel, stream: bool, conversation: Optional[_BaseConversation] = ...) -> None:
        ...
    
    def set_usage(self, *, input: Optional[int] = ..., output: Optional[int] = ..., details: Optional[dict] = ...):
        ...
    
    @classmethod
    def from_row(cls, db, row):
        ...
    
    def token_usage(self) -> str:
        ...
    
    def log_to_db(self, db):
        ...
    


class Response(_BaseResponse):
    model: Model
    conversation: Optional[Conversation] = ...
    def on_done(self, callback):
        ...
    
    def __str__(self) -> str:
        ...
    
    def text(self) -> str:
        ...
    
    def text_or_raise(self) -> str:
        ...
    
    def json(self) -> Optional[Dict[str, Any]]:
        ...
    
    def duration_ms(self) -> int:
        ...
    
    def datetime_utc(self) -> str:
        ...
    
    def usage(self) -> Usage:
        ...
    
    def __iter__(self) -> Iterator[str]:
        ...
    
    def __repr__(self):
        ...
    


class AsyncResponse(_BaseResponse):
    model: AsyncModel
    conversation: Optional[AsyncConversation] = ...
    async def on_done(self, callback):
        ...
    
    def __aiter__(self):
        ...
    
    async def __anext__(self) -> str:
        ...
    
    def text_or_raise(self) -> str:
        ...
    
    async def text(self) -> str:
        ...
    
    async def json(self) -> Optional[Dict[str, Any]]:
        ...
    
    async def duration_ms(self) -> int:
        ...
    
    async def datetime_utc(self) -> str:
        ...
    
    async def usage(self) -> Usage:
        ...
    
    def __await__(self):
        ...
    
    async def to_sync_response(self) -> Response:
        ...
    
    @classmethod
    def fake(cls, model: AsyncModel, prompt: str, *attachments: List[Attachment], system: str, response: str):
        "Utility method to help with writing tests"
        ...
    
    def __repr__(self):
        ...
    


class Options(BaseModel):
    class Config:
        extra = ...
    
    


_Options = Options
class _get_key_mixin:
    def get_key(self):
        ...
    


class _BaseModel(ABC, _get_key_mixin):
    model_id: str
    key: Optional[str] = ...
    needs_key: Optional[str] = ...
    key_env_var: Optional[str] = ...
    can_stream: bool = ...
    attachment_types: Set = ...
    class Options(_Options):
        ...
    
    
    def __str__(self) -> str:
        ...
    
    def __repr__(self):
        ...
    


class Model(_BaseModel):
    def conversation(self) -> Conversation:
        ...
    
    @abstractmethod
    def execute(self, prompt: Prompt, stream: bool, response: Response, conversation: Optional[Conversation]) -> Iterator[str]:
        ...
    
    def prompt(self, prompt: str, *, attachments: Optional[List[Attachment]] = ..., system: Optional[str] = ..., stream: bool = ..., **options) -> Response:
        ...
    


class AsyncModel(_BaseModel):
    def conversation(self) -> AsyncConversation:
        ...
    
    @abstractmethod
    async def execute(self, prompt: Prompt, stream: bool, response: AsyncResponse, conversation: Optional[AsyncConversation]) -> AsyncGenerator[str, None]:
        ...
    
    def prompt(self, prompt: str, *, attachments: Optional[List[Attachment]] = ..., system: Optional[str] = ..., stream: bool = ..., **options) -> AsyncResponse:
        ...
    


class EmbeddingModel(ABC, _get_key_mixin):
    model_id: str
    key: Optional[str] = ...
    needs_key: Optional[str] = ...
    key_env_var: Optional[str] = ...
    supports_text: bool = ...
    supports_binary: bool = ...
    batch_size: Optional[int] = ...
    def embed(self, item: Union[str, bytes]) -> List[float]:
        "Embed a single text string or binary blob, return a list of floats"
        ...
    
    def embed_multi(self, items: Iterable[Union[str, bytes]], batch_size: Optional[int] = ...) -> Iterator[List[float]]:
        "Embed multiple items in batches according to the model batch_size"
        ...
    
    @abstractmethod
    def embed_batch(self, items: Iterable[Union[str, bytes]]) -> Iterator[List[float]]:
        """
        Embed a batch of strings or blobs, return a list of lists of floats
        """
        ...
    


@dataclass
class ModelWithAliases:
    model: Model
    async_model: AsyncModel
    aliases: Set[str]
    ...


@dataclass
class EmbeddingModelWithAliases:
    model: EmbeddingModel
    aliases: Set[str]
    ...


